{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "from time import sleep\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admini\\Anaconda3\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "import efficientnet.tfkeras\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admini\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:507: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n"
     ]
    }
   ],
   "source": [
    "classifier = load_model('Emotion_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "names = {'Unknown': 0,'Akshay': 1, 'Khushal': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample picture and learn how to recognize it.\n",
    "akshay_image = face_recognition.load_image_file(\"Akshay.jpg\")\n",
    "akshay_face_encoding = face_recognition.face_encodings(akshay_image)[0]\n",
    "\n",
    "# Load a second sample picture and learn how to recognize it.\n",
    "khushal_image = face_recognition.load_image_file(\"Khushal.jpg\")\n",
    "khushal_face_encoding = face_recognition.face_encodings(khushal_image)[0]\n",
    "\n",
    "# Create arrays of known face encodings and their names\n",
    "known_face_encodings = [\n",
    "    akshay_face_encoding,\n",
    "    khushal_face_encoding\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Akshay\",\n",
    "    \"Khushal\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emotion_list = []\n",
    "Person_name = []\n",
    "Time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Unknown Neutral\n",
      "Unknown Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n",
      "Akshay Neutral\n"
     ]
    }
   ],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "labels = []\n",
    "process_this_frame = True\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    #Emotion detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,6)\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        #cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h,x:x+w]\n",
    "        roi_gray = cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        if np.sum([roi_gray])!=0:\n",
    "            roi = roi_gray.astype('float')/255.\n",
    "            roi = img_to_array(roi)\n",
    "            roi = np.expand_dims(roi,axis=0)\n",
    "            \n",
    "            preds = classifier.predict(roi)[0]\n",
    "            label = preds.argmax()\n",
    "            labels.append(label)\n",
    "            label_position = (x,y)\n",
    "\n",
    "    # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            face_names.append(name)\n",
    "            \n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left), name, label in zip(face_locations, face_names, labels):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 30), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        overlay_text = \"%s %s\" % (name, class_labels[label])\n",
    "        print(name, class_labels[label])\n",
    "        cv2.putText(frame, overlay_text, (left + 7, bottom - 7), font, 0.8, (255, 255, 255), 1)\n",
    "        \n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        Time.append(current_time)\n",
    "        Person_name.append(names[name])\n",
    "        Emotion_list.append(label)\n",
    "        \n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updateing Emotion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Time':Time,\n",
    "        'Person':Person_name,\n",
    "        'Emotion':Emotion_list}\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Person</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09:30:39</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09:30:39</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09:30:40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09:30:40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09:30:41</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time  Person  Emotion\n",
       "0  09:30:39       1        4\n",
       "1  09:30:39       1        4\n",
       "2  09:30:40       1        4\n",
       "3  09:30:40       1        4\n",
       "4  09:30:41       1        4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('Emotion_data.csv')\n",
    "#data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Person</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23:26:32</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23:26:34</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23:26:34</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23:26:36</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23:26:36</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time  Person  Emotion\n",
       "0  23:26:32       1        6\n",
       "1  23:26:34       1        6\n",
       "2  23:26:34       1        6\n",
       "3  23:26:36       1        6\n",
       "4  23:26:36       1        6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.concat([data, data1],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Person</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09:30:39</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09:30:39</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09:30:40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09:30:40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09:30:41</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time  Person  Emotion\n",
       "0  09:30:39       1        4\n",
       "1  09:30:39       1        4\n",
       "2  09:30:40       1        4\n",
       "3  09:30:40       1        4\n",
       "4  09:30:41       1        4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv('Emotion_data.csv',index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('Emotion_data.csv')\n",
    "#data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data2['Emotion'].plot(kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "datax = data2[data2['Person'] == 1]\n",
    "datax['Emotion'].plot(kind='hist',xlim=[0,6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Notification(data):\n",
    "    # inistionlization varibales\n",
    "    Angry = Disgust = Fear = Happy = Sad = Surprise = Neutral = 0\n",
    "    #setting values of varibales\n",
    "    for i in data['Emotion']:\n",
    "        if i == 0:\n",
    "            Angry = Angry + 1\n",
    "        elif i == 1:\n",
    "            Disgust = Disgust + 1\n",
    "        elif i == 2:\n",
    "            Fear = Fear + 1\n",
    "        elif i == 3:\n",
    "            Happy = Happy + 1\n",
    "        elif i == 4:\n",
    "            Sad = Sad + 1\n",
    "        elif i == 5:\n",
    "            Surprise = Surprise + 1\n",
    "        else:\n",
    "            Neutral = Neutral + 1\n",
    "    \n",
    "    # multiplying with weigths\n",
    "    Angry = Angry * 1\n",
    "    Disgust = Disgust * 1.2\n",
    "    Fear = Fear * 1.3\n",
    "    Happy = Happy * 1\n",
    "    Sad = Sad * 1.3\n",
    "    Surprise = Surprise * 1\n",
    "    Neutral = Neutral *0.2\n",
    "    \n",
    "    depression = Neutral + Sad + Disgust\n",
    "    joyful = Happy + Neutral\n",
    "    Aggrasive = Angry\n",
    "    \n",
    "    # Notification\n",
    "    if depression > joyful and depression > Aggrasive:\n",
    "        print('Depression')\n",
    "    elif joyful > depression and joyful > Aggrasive:\n",
    "        print('Good Mood')\n",
    "    else:\n",
    "        print(\"Aggression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depression\n"
     ]
    }
   ],
   "source": [
    "datax = data2[data2['Person'] == 1]\n",
    "Notification(datax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Add new Face\n",
    "2. collecting data\n",
    "3. analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
